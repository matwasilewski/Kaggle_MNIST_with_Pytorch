{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import autograd\n",
    "from torch.utils import data\n",
    "from torch.backends import cudnn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HYPERPARAMETER & CONFIGURATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "max_epochs = 10\n",
    "n_batches = 42\n",
    "batch_size = 800\n",
    "\n",
    "params = {'batch_size': 420,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6,\n",
    "          'learning_rate' : 0.01}\n",
    "\n",
    "max_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PRINTING DIGITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINTING HANDLING HERE\n",
    "def print_digit(image):\n",
    "    # digits_train.head()\n",
    "    image = image.view(28, 28)\n",
    "    plt.figure(1, figsize=(3, 3))\n",
    "    plt.imshow(image.numpy(), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "def random_digit(X, y):\n",
    "    x = rd.randint(0, X[:,0].shape[0])\n",
    "    \n",
    "    print_digit(X[x,:])\n",
    "    print(y[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASET CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(data.IterableDataset):\n",
    "    'Custom MNIST dataset for Kaggle challange'\n",
    "    def __init__(self, path):\n",
    "        'Initialization'\n",
    "        self.X, self.y = self.__preprocessData(path)\n",
    "        \n",
    "    def __preprocessData(self, path):\n",
    "        digits_train = pd.read_csv(path)\n",
    "        \n",
    "        train_tensor = torch.tensor(digits_train.drop('label', axis=1).to_numpy(), dtype=torch.int32)\n",
    "        labels_tensor = torch.tensor(digits_train['label'].to_numpy()) \n",
    "        \n",
    "        return train_tensor, labels_tensor\n",
    "    \n",
    "    def __iter__(self, start=0, end=-1):\n",
    "        \n",
    "        return iter(zip(self.X[start : end], self.y[start : end]))\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = MNIST('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in iter(validation):\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NEURAL NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # three layers, input -> 250 -> 250 -> 10\n",
    "        self.linear1 = nn.Linear(784, 250)\n",
    "        self.linear2 = nn.Linear(250, 250)\n",
    "        self.linear3 = nn.Linear(250, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # activation functions between layers\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "# TODO partition dataset into validation and training data\n",
    "partition = # IDs\n",
    "# Add labels\n",
    "labels = # Labels\n",
    "\n",
    "# Generators\n",
    "training_set = Dataset(partition['train'], labels)\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "validation_set = Dataset(partition['validation'], labels)\n",
    "validation_generator = data.DataLoader(validation_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over epochs\n",
    "for epoch in range(max_epochs):\n",
    "    # Training\n",
    "    for local_batch, local_labels in training_generator:\n",
    "        # Transfer to GPU\n",
    "        local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "\n",
    "        # Model computations\n",
    "        [...]\n",
    "\n",
    "    # Validation\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for local_batch, local_labels in validation_generator:\n",
    "            # Transfer to GPU\n",
    "            local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "\n",
    "            # Model computations\n",
    "            [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data overview\n",
    "# print(digits_train.shape)\n",
    "# print(digits_submission.shape)\n",
    "# print(digits_train.loc[:,'label'].value_counts())\n",
    "\n",
    "\n",
    "# # Returns ((n_samples, pixels), n_sample)\n",
    "# def preprocess_labeled_data_into_tensors(df, label='label'):\n",
    "#     train_tensor = torch.tensor(df.drop(label, axis=1).to_numpy(), dtype=torch.float)\n",
    "#     labels_tensor = torch.tensor(df[label].to_numpy()) \n",
    "    \n",
    "#     return train_tensor, labels_tensor\n",
    "\n",
    "# # Returns ((n_samples, pixels), n_sample)\n",
    "# def preprocess_unlabeled_data_into_tensor(df):\n",
    "#     test = torch.tensor(df.to_numpy())\n",
    "    \n",
    "#     return test\n",
    "\n",
    "# # training data: nr_batches x (data, target)\n",
    "# # data : tensor (elements_in_batch, 28, 28)\n",
    "# # target : tensor (elements_in_batch, 1)\n",
    "# def batch_data(X, y):\n",
    "#     training = []\n",
    "\n",
    "#     for i in range(n_batches):\n",
    "#         # Local batches and labels\n",
    "#         local_X, local_y = X_train[i * batch_size : (i + 1) * batch_size, ], y_train[i * batch_size : (i + 1) * batch_size, ]\n",
    "#         training.append((local_X, local_y))\n",
    "        \n",
    "#     return training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(training_data):\n",
    "    for epoch in range(max_epochs):\n",
    "        # training data: nr_batches x (data, target)\n",
    "        # data : tensor (elements_in_batch, 28, 28) NOPE\n",
    "        # target : tensor (elements_in_batch, 1)\n",
    "        for batch_idx, (data, target) in enumerate(training_data):\n",
    "            data, target = autograd.Variable(data), autograd.Variable(target)            \n",
    "            # resize data from (batch_size, 1, 28, 28) to (batch_size, 28*28)\n",
    "            # data = data.view(-1, 28*28)\n",
    "            print(data.shape)\n",
    "            # zero gradients to prevent accumulation\n",
    "            optimizer.zero_grad()\n",
    "            # nn output\n",
    "            # nSamples * nChannels? * nPixels\n",
    "            \n",
    "            # input = torch.randn(1, 784)\n",
    "            # out = net(input)\n",
    "            # print(out)\n",
    "            # print(out.shape)\n",
    "            print(data.shape)\n",
    "            net_out = net(data)\n",
    "            # get loss\n",
    "            loss = criterion(net_out, target)\n",
    "            # backpropagate\n",
    "            loss.backward()\n",
    "            # optimization step\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(training_data.dataset),\n",
    "                               100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "                \n",
    "# train_nn(train_batched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create NNet instance and initialize optimizer and criterion\n",
    "net = Net()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "criterion = nn.NLLLoss()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = preprocess_labeled_data_into_tensors(digits_train)    \n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition data\n",
    "X_train, X_test,y_train,y_test = train_test_split(X, y, test_size=0.2)\n",
    "train_batched = batch_data(X_train, y_train)\n",
    "print(train_batched[0][0].shape)\n",
    "print(train_batched[0][1].shape)\n",
    "print(len(train_batched))\n",
    "# train_nn(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nn(train_batched)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
