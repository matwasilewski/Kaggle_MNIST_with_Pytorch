{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import autograd\n",
    "from torch.utils import data\n",
    "from torch.backends import cudnn\n",
    "import utils\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.dataLoader\n",
    "from utils.digitPrinter import print_digit\n",
    "from utils.dataLoader import get_train_valid_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HYPERPARAMETER & CONFIGURATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "max_epochs = 20\n",
    "batch_size = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NEURAL NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # three layers, input -> 250 -> 250 -> 10\n",
    "        self.linear1 = nn.Linear(784, 250)\n",
    "        self.linear2 = nn.Linear(250, 250)\n",
    "        self.linear3 = nn.Linear(250, 250)\n",
    "        self.linear4 = nn.Linear(250, 100)\n",
    "        self.linear5 = nn.Linear(100, 100)\n",
    "        self.linear6 = nn.Linear(100, 100)\n",
    "        self.linear7 = nn.Linear(100, 50)\n",
    "        self.linear8 = nn.Linear(50, 50)\n",
    "        self.linear9 = nn.Linear(50, 25)\n",
    "        self.linear10 = nn.Linear(25, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # activation functions between layers\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        x = F.relu(self.linear4(x))\n",
    "        x = F.relu(self.linear5(x))\n",
    "        x = F.relu(self.linear6(x))\n",
    "        x = F.relu(self.linear7(x))\n",
    "        x = F.relu(self.linear8(x))\n",
    "        x = F.relu(self.linear9(x))\n",
    "        x = self.linear10(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader = get_train_valid_loader(\"data/train.csv\", batch_size, 10, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_digit(valid_loader, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (linear1): Linear(in_features=784, out_features=250, bias=True)\n",
      "  (linear2): Linear(in_features=250, out_features=250, bias=True)\n",
      "  (linear3): Linear(in_features=250, out_features=250, bias=True)\n",
      "  (linear4): Linear(in_features=250, out_features=100, bias=True)\n",
      "  (linear5): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (linear6): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (linear7): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (linear8): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (linear9): Linear(in_features=50, out_features=25, bias=True)\n",
      "  (linear10): Linear(in_features=25, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create NNet instance and initialize optimizer and criterion\n",
    "net = Net()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "criterion = nn.NLLLoss()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader = get_train_valid_loader(\"data/train.csv\", batch_size, 10, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/33600 (0%)]\tLoss: 2.318320\n",
      "Train Epoch: 0 [4000/33600 (12%)]\tLoss: 2.309738\n",
      "Train Epoch: 0 [8000/33600 (24%)]\tLoss: 2.313692\n",
      "Train Epoch: 0 [12000/33600 (36%)]\tLoss: 2.308182\n",
      "Train Epoch: 0 [16000/33600 (48%)]\tLoss: 2.299282\n",
      "Train Epoch: 0 [20000/33600 (60%)]\tLoss: 2.306010\n",
      "Train Epoch: 0 [24000/33600 (71%)]\tLoss: 2.296736\n",
      "Train Epoch: 0 [28000/33600 (83%)]\tLoss: 2.292753\n",
      "Train Epoch: 0 [32000/33600 (95%)]\tLoss: 2.278688\n",
      "Accuracy of the network on validation images: 17 %\n",
      "Train Epoch: 1 [0/33600 (0%)]\tLoss: 2.281184\n",
      "Train Epoch: 1 [4000/33600 (12%)]\tLoss: 2.262625\n",
      "Train Epoch: 1 [8000/33600 (24%)]\tLoss: 2.213019\n",
      "Train Epoch: 1 [12000/33600 (36%)]\tLoss: 2.163329\n",
      "Train Epoch: 1 [16000/33600 (48%)]\tLoss: 2.062081\n",
      "Train Epoch: 1 [20000/33600 (60%)]\tLoss: 2.009998\n",
      "Train Epoch: 1 [24000/33600 (71%)]\tLoss: 1.995417\n",
      "Train Epoch: 1 [28000/33600 (83%)]\tLoss: 1.886456\n",
      "Train Epoch: 1 [32000/33600 (95%)]\tLoss: 1.854651\n",
      "Accuracy of the network on validation images: 29 %\n",
      "Train Epoch: 2 [0/33600 (0%)]\tLoss: 1.819144\n",
      "Train Epoch: 2 [4000/33600 (12%)]\tLoss: 1.709308\n",
      "Train Epoch: 2 [8000/33600 (24%)]\tLoss: 1.486450\n",
      "Train Epoch: 2 [12000/33600 (36%)]\tLoss: 2.894933\n",
      "Train Epoch: 2 [16000/33600 (48%)]\tLoss: 2.184764\n",
      "Train Epoch: 2 [20000/33600 (60%)]\tLoss: 2.050279\n",
      "Train Epoch: 2 [24000/33600 (71%)]\tLoss: 1.993038\n",
      "Train Epoch: 2 [28000/33600 (83%)]\tLoss: 1.853168\n",
      "Train Epoch: 2 [32000/33600 (95%)]\tLoss: 1.822713\n",
      "Accuracy of the network on validation images: 29 %\n",
      "Train Epoch: 3 [0/33600 (0%)]\tLoss: 1.752197\n",
      "Train Epoch: 3 [4000/33600 (12%)]\tLoss: 1.732229\n",
      "Train Epoch: 3 [8000/33600 (24%)]\tLoss: 1.521737\n",
      "Train Epoch: 3 [12000/33600 (36%)]\tLoss: 1.560728\n",
      "Train Epoch: 3 [16000/33600 (48%)]\tLoss: 1.340342\n",
      "Train Epoch: 3 [20000/33600 (60%)]\tLoss: 1.244785\n",
      "Train Epoch: 3 [24000/33600 (71%)]\tLoss: 2.116871\n",
      "Train Epoch: 3 [28000/33600 (83%)]\tLoss: 2.008249\n",
      "Train Epoch: 3 [32000/33600 (95%)]\tLoss: 2.024354\n",
      "Accuracy of the network on validation images: 23 %\n",
      "Train Epoch: 4 [0/33600 (0%)]\tLoss: 1.987324\n",
      "Train Epoch: 4 [4000/33600 (12%)]\tLoss: 1.918337\n",
      "Train Epoch: 4 [8000/33600 (24%)]\tLoss: 1.847810\n",
      "Train Epoch: 4 [12000/33600 (36%)]\tLoss: 1.793493\n",
      "Train Epoch: 4 [16000/33600 (48%)]\tLoss: 1.668726\n",
      "Train Epoch: 4 [20000/33600 (60%)]\tLoss: 1.598317\n",
      "Train Epoch: 4 [24000/33600 (71%)]\tLoss: 1.460876\n",
      "Train Epoch: 4 [28000/33600 (83%)]\tLoss: 1.394634\n",
      "Train Epoch: 4 [32000/33600 (95%)]\tLoss: 1.312488\n",
      "Accuracy of the network on validation images: 46 %\n",
      "Train Epoch: 5 [0/33600 (0%)]\tLoss: 1.412402\n",
      "Train Epoch: 5 [4000/33600 (12%)]\tLoss: 1.637483\n",
      "Train Epoch: 5 [8000/33600 (24%)]\tLoss: 1.886971\n",
      "Train Epoch: 5 [12000/33600 (36%)]\tLoss: 1.866142\n",
      "Train Epoch: 5 [16000/33600 (48%)]\tLoss: 1.645309\n",
      "Train Epoch: 5 [20000/33600 (60%)]\tLoss: 1.591992\n",
      "Train Epoch: 5 [24000/33600 (71%)]\tLoss: 1.407370\n",
      "Train Epoch: 5 [28000/33600 (83%)]\tLoss: 1.282042\n",
      "Train Epoch: 5 [32000/33600 (95%)]\tLoss: 1.232268\n",
      "Accuracy of the network on validation images: 43 %\n",
      "Train Epoch: 6 [0/33600 (0%)]\tLoss: 1.250549\n",
      "Train Epoch: 6 [4000/33600 (12%)]\tLoss: 1.182217\n",
      "Train Epoch: 6 [8000/33600 (24%)]\tLoss: 1.115409\n",
      "Train Epoch: 6 [12000/33600 (36%)]\tLoss: 1.060422\n",
      "Train Epoch: 6 [16000/33600 (48%)]\tLoss: 1.162723\n",
      "Train Epoch: 6 [20000/33600 (60%)]\tLoss: 1.015147\n",
      "Train Epoch: 6 [24000/33600 (71%)]\tLoss: 0.943217\n",
      "Train Epoch: 6 [28000/33600 (83%)]\tLoss: 0.969175\n",
      "Train Epoch: 6 [32000/33600 (95%)]\tLoss: 1.019459\n",
      "Accuracy of the network on validation images: 73 %\n",
      "Train Epoch: 7 [0/33600 (0%)]\tLoss: 0.935759\n",
      "Train Epoch: 7 [4000/33600 (12%)]\tLoss: 0.868833\n",
      "Train Epoch: 7 [8000/33600 (24%)]\tLoss: 0.876696\n",
      "Train Epoch: 7 [12000/33600 (36%)]\tLoss: 0.830584\n",
      "Train Epoch: 7 [16000/33600 (48%)]\tLoss: 0.851329\n",
      "Train Epoch: 7 [20000/33600 (60%)]\tLoss: 0.701182\n",
      "Train Epoch: 7 [24000/33600 (71%)]\tLoss: 0.629947\n",
      "Train Epoch: 7 [28000/33600 (83%)]\tLoss: 0.605705\n",
      "Train Epoch: 7 [32000/33600 (95%)]\tLoss: 0.588045\n",
      "Accuracy of the network on validation images: 85 %\n",
      "Train Epoch: 8 [0/33600 (0%)]\tLoss: 0.541295\n",
      "Train Epoch: 8 [4000/33600 (12%)]\tLoss: 0.411200\n",
      "Train Epoch: 8 [8000/33600 (24%)]\tLoss: 0.383523\n",
      "Train Epoch: 8 [12000/33600 (36%)]\tLoss: 0.325657\n",
      "Train Epoch: 8 [16000/33600 (48%)]\tLoss: 0.270170\n",
      "Train Epoch: 8 [20000/33600 (60%)]\tLoss: 0.368335\n",
      "Train Epoch: 8 [24000/33600 (71%)]\tLoss: 0.279910\n",
      "Train Epoch: 8 [28000/33600 (83%)]\tLoss: 0.214975\n",
      "Train Epoch: 8 [32000/33600 (95%)]\tLoss: 0.304526\n",
      "Accuracy of the network on validation images: 92 %\n",
      "Train Epoch: 9 [0/33600 (0%)]\tLoss: 0.303919\n",
      "Train Epoch: 9 [4000/33600 (12%)]\tLoss: 0.253580\n",
      "Train Epoch: 9 [8000/33600 (24%)]\tLoss: 0.321173\n",
      "Train Epoch: 9 [12000/33600 (36%)]\tLoss: 0.228577\n",
      "Train Epoch: 9 [16000/33600 (48%)]\tLoss: 0.205086\n",
      "Train Epoch: 9 [20000/33600 (60%)]\tLoss: 0.257547\n",
      "Train Epoch: 9 [24000/33600 (71%)]\tLoss: 0.259911\n",
      "Train Epoch: 9 [28000/33600 (83%)]\tLoss: 0.269812\n",
      "Train Epoch: 9 [32000/33600 (95%)]\tLoss: 0.204452\n",
      "Accuracy of the network on validation images: 93 %\n",
      "Train Epoch: 10 [0/33600 (0%)]\tLoss: 0.256806\n",
      "Train Epoch: 10 [4000/33600 (12%)]\tLoss: 0.213344\n",
      "Train Epoch: 10 [8000/33600 (24%)]\tLoss: 0.206852\n",
      "Train Epoch: 10 [12000/33600 (36%)]\tLoss: 0.214110\n",
      "Train Epoch: 10 [16000/33600 (48%)]\tLoss: 0.180548\n",
      "Train Epoch: 10 [20000/33600 (60%)]\tLoss: 0.169548\n",
      "Train Epoch: 10 [24000/33600 (71%)]\tLoss: 0.186300\n",
      "Train Epoch: 10 [28000/33600 (83%)]\tLoss: 0.173705\n",
      "Train Epoch: 10 [32000/33600 (95%)]\tLoss: 0.189993\n",
      "Accuracy of the network on validation images: 93 %\n",
      "Train Epoch: 11 [0/33600 (0%)]\tLoss: 0.173762\n",
      "Train Epoch: 11 [4000/33600 (12%)]\tLoss: 0.224643\n",
      "Train Epoch: 11 [8000/33600 (24%)]\tLoss: 0.176779\n",
      "Train Epoch: 11 [12000/33600 (36%)]\tLoss: 0.179292\n",
      "Train Epoch: 11 [16000/33600 (48%)]\tLoss: 0.119231\n",
      "Train Epoch: 11 [20000/33600 (60%)]\tLoss: 0.149598\n",
      "Train Epoch: 11 [24000/33600 (71%)]\tLoss: 0.144383\n",
      "Train Epoch: 11 [28000/33600 (83%)]\tLoss: 0.158064\n",
      "Train Epoch: 11 [32000/33600 (95%)]\tLoss: 0.148904\n",
      "Accuracy of the network on validation images: 95 %\n",
      "Train Epoch: 12 [0/33600 (0%)]\tLoss: 0.129649\n",
      "Train Epoch: 12 [4000/33600 (12%)]\tLoss: 0.138027\n",
      "Train Epoch: 12 [8000/33600 (24%)]\tLoss: 0.148389\n",
      "Train Epoch: 12 [12000/33600 (36%)]\tLoss: 0.106881\n",
      "Train Epoch: 12 [16000/33600 (48%)]\tLoss: 0.131962\n",
      "Train Epoch: 12 [20000/33600 (60%)]\tLoss: 0.115717\n",
      "Train Epoch: 12 [24000/33600 (71%)]\tLoss: 0.087139\n",
      "Train Epoch: 12 [28000/33600 (83%)]\tLoss: 0.151327\n",
      "Train Epoch: 12 [32000/33600 (95%)]\tLoss: 0.107966\n",
      "Accuracy of the network on validation images: 95 %\n",
      "Train Epoch: 13 [0/33600 (0%)]\tLoss: 0.115000\n",
      "Train Epoch: 13 [4000/33600 (12%)]\tLoss: 0.072376\n",
      "Train Epoch: 13 [8000/33600 (24%)]\tLoss: 0.112061\n",
      "Train Epoch: 13 [12000/33600 (36%)]\tLoss: 0.095401\n",
      "Train Epoch: 13 [16000/33600 (48%)]\tLoss: 0.118925\n",
      "Train Epoch: 13 [20000/33600 (60%)]\tLoss: 0.109526\n",
      "Train Epoch: 13 [24000/33600 (71%)]\tLoss: 0.078384\n",
      "Train Epoch: 13 [28000/33600 (83%)]\tLoss: 0.102096\n",
      "Train Epoch: 13 [32000/33600 (95%)]\tLoss: 0.108747\n",
      "Accuracy of the network on validation images: 95 %\n",
      "Train Epoch: 14 [0/33600 (0%)]\tLoss: 0.076129\n",
      "Train Epoch: 14 [4000/33600 (12%)]\tLoss: 0.065514\n",
      "Train Epoch: 14 [8000/33600 (24%)]\tLoss: 0.090925\n",
      "Train Epoch: 14 [12000/33600 (36%)]\tLoss: 0.064173\n",
      "Train Epoch: 14 [16000/33600 (48%)]\tLoss: 0.112699\n",
      "Train Epoch: 14 [20000/33600 (60%)]\tLoss: 0.076359\n",
      "Train Epoch: 14 [24000/33600 (71%)]\tLoss: 0.062311\n",
      "Train Epoch: 14 [28000/33600 (83%)]\tLoss: 0.091028\n",
      "Train Epoch: 14 [32000/33600 (95%)]\tLoss: 0.085524\n",
      "Accuracy of the network on validation images: 95 %\n",
      "Train Epoch: 15 [0/33600 (0%)]\tLoss: 0.076320\n",
      "Train Epoch: 15 [4000/33600 (12%)]\tLoss: 0.098252\n",
      "Train Epoch: 15 [8000/33600 (24%)]\tLoss: 0.052783\n",
      "Train Epoch: 15 [12000/33600 (36%)]\tLoss: 0.072982\n",
      "Train Epoch: 15 [16000/33600 (48%)]\tLoss: 0.082108\n",
      "Train Epoch: 15 [20000/33600 (60%)]\tLoss: 0.071387\n",
      "Train Epoch: 15 [24000/33600 (71%)]\tLoss: 0.072336\n",
      "Train Epoch: 15 [28000/33600 (83%)]\tLoss: 0.087714\n",
      "Train Epoch: 15 [32000/33600 (95%)]\tLoss: 0.054180\n",
      "Accuracy of the network on validation images: 95 %\n",
      "Train Epoch: 16 [0/33600 (0%)]\tLoss: 0.063627\n",
      "Train Epoch: 16 [4000/33600 (12%)]\tLoss: 0.050850\n",
      "Train Epoch: 16 [8000/33600 (24%)]\tLoss: 0.077020\n",
      "Train Epoch: 16 [12000/33600 (36%)]\tLoss: 0.062043\n",
      "Train Epoch: 16 [16000/33600 (48%)]\tLoss: 0.077679\n",
      "Train Epoch: 16 [20000/33600 (60%)]\tLoss: 0.089080\n",
      "Train Epoch: 16 [24000/33600 (71%)]\tLoss: 0.071876\n",
      "Train Epoch: 16 [28000/33600 (83%)]\tLoss: 0.084294\n",
      "Train Epoch: 16 [32000/33600 (95%)]\tLoss: 0.063777\n",
      "Accuracy of the network on validation images: 95 %\n",
      "Train Epoch: 17 [0/33600 (0%)]\tLoss: 0.073386\n",
      "Train Epoch: 17 [4000/33600 (12%)]\tLoss: 0.054934\n",
      "Train Epoch: 17 [8000/33600 (24%)]\tLoss: 0.042223\n",
      "Train Epoch: 17 [12000/33600 (36%)]\tLoss: 0.047886\n",
      "Train Epoch: 17 [16000/33600 (48%)]\tLoss: 0.076408\n",
      "Train Epoch: 17 [20000/33600 (60%)]\tLoss: 0.062904\n",
      "Train Epoch: 17 [24000/33600 (71%)]\tLoss: 0.047774\n",
      "Train Epoch: 17 [28000/33600 (83%)]\tLoss: 0.071223\n",
      "Train Epoch: 17 [32000/33600 (95%)]\tLoss: 0.055222\n",
      "Accuracy of the network on validation images: 96 %\n",
      "Train Epoch: 18 [0/33600 (0%)]\tLoss: 0.053164\n",
      "Train Epoch: 18 [4000/33600 (12%)]\tLoss: 0.023317\n",
      "Train Epoch: 18 [8000/33600 (24%)]\tLoss: 0.029735\n",
      "Train Epoch: 18 [12000/33600 (36%)]\tLoss: 0.041680\n",
      "Train Epoch: 18 [16000/33600 (48%)]\tLoss: 0.050007\n",
      "Train Epoch: 18 [20000/33600 (60%)]\tLoss: 0.064173\n",
      "Train Epoch: 18 [24000/33600 (71%)]\tLoss: 0.054817\n",
      "Train Epoch: 18 [28000/33600 (83%)]\tLoss: 0.075052\n",
      "Train Epoch: 18 [32000/33600 (95%)]\tLoss: 0.029366\n",
      "Accuracy of the network on validation images: 96 %\n",
      "Train Epoch: 19 [0/33600 (0%)]\tLoss: 0.019956\n",
      "Train Epoch: 19 [4000/33600 (12%)]\tLoss: 0.025950\n",
      "Train Epoch: 19 [8000/33600 (24%)]\tLoss: 0.034023\n",
      "Train Epoch: 19 [12000/33600 (36%)]\tLoss: 0.032907\n",
      "Train Epoch: 19 [16000/33600 (48%)]\tLoss: 0.036424\n",
      "Train Epoch: 19 [20000/33600 (60%)]\tLoss: 0.027885\n",
      "Train Epoch: 19 [24000/33600 (71%)]\tLoss: 0.028918\n",
      "Train Epoch: 19 [28000/33600 (83%)]\tLoss: 0.042636\n",
      "Train Epoch: 19 [32000/33600 (95%)]\tLoss: 0.038303\n",
      "Accuracy of the network on validation images: 95 %\n"
     ]
    }
   ],
   "source": [
    "# Loop over epochs\n",
    "for epoch in range(max_epochs):\n",
    "    # Training\n",
    "    batch_idx = 0\n",
    "    for local_train in train_loader:\n",
    "        # Transfer to GPU\n",
    "        local_batch = local_train['image']\n",
    "        local_labels = local_train['label']\n",
    "        \n",
    "        # print(local_batch.shape)\n",
    "        # print(local_labels.shape)\n",
    "        local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "        \n",
    "        # Model computations\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = net(local_batch.float())\n",
    "        loss = criterion(output, local_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 5 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(local_batch), len(train_loader.sampler.indices),\n",
    "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
    "        \n",
    "        batch_idx += 1        \n",
    "\n",
    "        \n",
    "    # Validation\n",
    "    with torch.set_grad_enabled(False):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for local_validate in valid_loader:\n",
    "            # Transfer to GPU\n",
    "            local_batch = local_validate['image']\n",
    "            local_labels = local_validate['label']\n",
    "        \n",
    "            local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "                \n",
    "            outputs = net(local_batch.float())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += len(local_labels)\n",
    "            correct += (predicted == local_labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on validation images: %d %%' % (\n",
    "            100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
